<!-- openaichatComponent.html -->
<div id="openaichatComponent" class="flex flex-col justify-between w-full h-full max-w-2xl mx-auto">
    <!-- Chat bubbles container (scrollable) -->
    <div id="chatContainer" class="flex-1 overflow-y-auto p-4 space-y-4">
        <!-- Messages will be dynamically appended here -->
    </div>
    <!-- Chat input at the bottom -->
    <div class="p-4 border-t border-gray-200">
        <div class="flex items-center gap-2">
            <select id="modelSelect" class="input input-bordered">
                <option value="gpt-3.5-turbo">GPT-3.5 Turbo</option>
                <option value="gpt-4o">GPT-4o</option>
                <!-- Add more models as needed -->
            </select>
            <input type="text" id="userInput" class="input input-bordered flex-grow" placeholder="Enter your message..." onkeypress="handleKeyPress(event)" />
            <button class="btn " onclick="sendPrompt()">Send</button>
        </div>
    </div>

    <script>
        let conversationHistory = [];

        function handleKeyPress(event) {
            if (event.key === "Enter") {
                sendPrompt();
            }
        }

        async function sendPrompt() {
            const inputField = document.getElementById("userInput");
            const userMessage = inputField.value.trim();
            inputField.value = "";

            if (!userMessage) return;

            appendMessage(userMessage, 'user'); // Show user's message
            const loadingElement = createLoadingElement();
            const chatContainer = document.getElementById("chatContainer");
            chatContainer.appendChild(loadingElement);
            scrollToBottom();

            const selectedModel = document.getElementById("modelSelect").value; // Get selected model

            const requestBody = {
                input: {
                    input: {
                        prompt: userMessage,
                        conversationHistory: conversationHistory,
                        model: selectedModel // Include selected model in the request
                    }
                }
            };

            try {
                const response = await fetch("https://frontendserver.de/api/askOpenAI", {
                    method: "POST",
                    headers: { "Content-Type": "application/json" },
                    body: JSON.stringify(requestBody)
                });

                if (!response.ok) {
                    throw new Error(`HTTP error! Status: ${response.status}`);
                }

                // Stream the response
                const reader = response.body.getReader();
                const decoder = new TextDecoder();
                let done = false;
                let tokenBuffer = '';
                let aiResponseText = '';

                while (!done) {
                    const { value, done: readerDone } = await reader.read();
                    done = readerDone;

                    if (value) {
                        tokenBuffer += decoder.decode(value, { stream: true });
                        const tokens = tokenBuffer.split('\n');
                        tokenBuffer = tokens.pop(); // Retain incomplete token

                        tokens.forEach(token => {
                            if (token.trim()) {
                                try {
                                    const parsed = JSON.parse(token);
                                    aiResponseText += parsed.response;
                                    loadingElement.textContent = aiResponseText;
                                    scrollToBottom();
                                } catch (error) {
                                    console.error("Error parsing token:", error);
                                }
                            }
                        });
                    }
                }

                loadingElement.textContent = aiResponseText; // Replace loader with final response
                conversationHistory.push({ role: 'assistant', content: aiResponseText });

            } catch (error) {
                loadingElement.textContent = `Error: ${error.message}`;
            }
        }

        function createMessageElement(message, sender) {
            const messageElement = document.createElement("div");
            messageElement.classList.add("chat", sender === 'user' ? "chat-end" : "chat-start");
            const bubbleElement = document.createElement("div");
            bubbleElement.classList.add("chat-bubble");
            bubbleElement.textContent = message;
            messageElement.appendChild(bubbleElement);
            return messageElement;
        }

        function createLoadingElement() {
            const loadingElement = document.createElement("div");
            loadingElement.classList.add("chat", "chat-start");
            const spinnerElement = document.createElement("span");
            spinnerElement.classList.add("loading", "loading-ring", "loading-sm");
            loadingElement.appendChild(spinnerElement);
            return loadingElement;
        }

        function appendMessage(message, sender) {
            const messageElement = createMessageElement(message, sender);
            const chatContainer = document.getElementById("chatContainer");
            chatContainer.appendChild(messageElement);
            scrollToBottom();
        }

        function scrollToBottom() {
            const chatContainer = document.getElementById("chatContainer");
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }
    </script>
</div>
